<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant Interface</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .container {
            width: 90%;
            max-width: 800px;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 300;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .main-content {
            padding: 40px;
        }

        .status-panel {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 30px;
            text-align: center;
        }

        .status-indicator {
            display: inline-block;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            margin-right: 10px;
            vertical-align: middle;
        }

        .status-ready { background: #28a745; }
        .status-connecting { background: #ffc107; }
        .status-active { background: #007bff; }
        .status-error { background: #dc3545; }

        .status-text {
            font-size: 1.2em;
            font-weight: 500;
            vertical-align: middle;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 30px 0;
        }

        .btn {
            padding: 15px 30px;
            border: none;
            border-radius: 50px;
            font-size: 1.1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            min-width: 150px;
        }

        .btn-primary {
            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
            color: white;
            box-shadow: 0 4px 15px rgba(40, 167, 69, 0.3);
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(40, 167, 69, 0.4);
        }

        .btn-danger {
            background: linear-gradient(135deg, #dc3545 0%, #e74c3c 100%);
            color: white;
            box-shadow: 0 4px 15px rgba(220, 53, 69, 0.3);
        }

        .btn-danger:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(220, 53, 69, 0.4);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none !important;
        }

        .conversation {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 25px;
            min-height: 300px;
            max-height: 500px;
            overflow-y: auto;
            margin: 30px 0;
        }

        .message {
            margin: 15px 0;
            padding: 15px 20px;
            border-radius: 18px;
            max-width: 80%;
            animation: slideIn 0.3s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            background: linear-gradient(135deg, #007bff 0%, #0056b3 100%);
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
            color: white;
        }

        .message.system {
            background: linear-gradient(135deg, #6c757d 0%, #495057 100%);
            color: white;
            text-align: center;
            margin: 0 auto;
            font-style: italic;
            max-width: 60%;
        }

        .message.error {
            background: linear-gradient(135deg, #dc3545 0%, #c82333 100%);
            color: white;
            text-align: center;
            margin: 0 auto;
            max-width: 70%;
        }

        .mic-button {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
            border: none;
            color: white;
            font-size: 2em;
            cursor: pointer;
            margin: 20px auto;
            display: block;
            transition: all 0.3s ease;
            box-shadow: 0 8px 25px rgba(40, 167, 69, 0.3);
        }

        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 12px 35px rgba(40, 167, 69, 0.4);
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #dc3545 0%, #c82333 100%);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .info-panel {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .debug-panel {
            background: #1a1a1a;
            color: #00ff00;
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            max-height: 200px;
            overflow-y: auto;
        }

        .debug-panel h4 {
            color: #ffffff;
            margin-bottom: 10px;
        }

        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Voice Assistant</h1>
            <p>Click and hold to talk with your AI assistant</p>
        </div>

        <div class="main-content">
            <div class="status-panel">
                <span class="status-indicator status-ready" id="statusIndicator"></span>
                <span class="status-text" id="statusText">Ready to talk</span>
            </div>

            <div class="info-panel">
                <strong>How to use:</strong><br>
                1. Click and hold the microphone button<br>
                2. Speak your message<br>
                3. Release to send and hear the response<br>
                <em>This approach ensures reliable connection and clear audio quality.</em>
            </div>

            <button class="mic-button" id="micButton" onmousedown="startRecording()" onmouseup="stopRecording()" ontouchstart="startRecording()" ontouchend="stopRecording()">
                üé§
            </button>

            <div class="conversation" id="conversation">
                <div class="message system">
                    Welcome! Hold the microphone button and speak to your AI assistant.
                </div>
            </div>

            <div class="debug-panel">
                <h4>Debug Log</h4>
                <div id="debugLog">System initialized...</div>
            </div>
        </div>
    </div>

    <script>
        class VoiceAssistant {
            constructor() {
                this.isRecording = false;
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.audioContext = null;
                this.isConnected = false;
                this.sessionId = null;
                this.hasGreeted = false;
            }

            updateStatus(text, type = 'ready') {
                const indicator = document.getElementById('statusIndicator');
                const statusText = document.getElementById('statusText');
                
                indicator.className = `status-indicator status-${type}`;
                statusText.textContent = text;
                
                this.log(`Status: ${text} (${type})`);
            }

            log(message) {
                const debugLog = document.getElementById('debugLog');
                const timestamp = new Date().toISOString().split('T')[1].split('.')[0];
                debugLog.innerHTML += `<br>[${timestamp}] ${message}`;
                debugLog.scrollTop = debugLog.scrollHeight;
                console.log(`[VoiceAssistant] ${message}`);
            }

            addMessage(text, type = 'system') {
                const conversation = document.getElementById('conversation');
                const message = document.createElement('div');
                message.className = `message ${type}`;
                message.textContent = text;
                conversation.appendChild(message);
                conversation.scrollTop = conversation.scrollHeight;
            }

            async startRecording() {
                if (this.isRecording) return;

                try {
                    this.log('Starting recording...');
                    this.updateStatus('Requesting microphone access...', 'connecting');

                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });

                    this.audioChunks = [];
                    this.isRecording = true;

                    document.getElementById('micButton').classList.add('recording');
                    this.updateStatus('üé§ Recording - Speak now!', 'active');

                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                        }
                    };

                    this.mediaRecorder.onstop = () => {
                        this.processRecording();
                        stream.getTracks().forEach(track => track.stop());
                    };

                    this.mediaRecorder.start();
                    this.log('Recording started');

                } catch (error) {
                    this.log(`Recording error: ${error.message}`);
                    this.updateStatus('Microphone access denied', 'error');
                    this.addMessage(`‚ùå ${error.message}`, 'error');
                }
            }

            stopRecording() {
                if (!this.isRecording || !this.mediaRecorder) return;

                this.log('Stopping recording...');
                this.isRecording = false;
                document.getElementById('micButton').classList.remove('recording');
                this.updateStatus('Processing audio...', 'connecting');

                this.mediaRecorder.stop();
            }

            async processRecording() {
                try {
                    this.log('Processing recorded audio...');
                    
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    this.log(`Audio blob size: ${audioBlob.size} bytes`);

                    if (audioBlob.size < 1000) {
                        this.addMessage('Recording too short, please try again', 'system');
                        this.updateStatus('Ready to talk', 'ready');
                        return;
                    }

                    // Send audio to server for processing
                    await this.sendAudioToServer(audioBlob);

                } catch (error) {
                    this.log(`Processing error: ${error.message}`);
                    this.updateStatus('Processing failed', 'error');
                    this.addMessage(`‚ùå ${error.message}`, 'error');
                }
            }

            async sendAudioToServer(audioBlob) {
                try {
                    this.updateStatus('Sending to AI...', 'connecting');
                    
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recording.webm');
                    if (this.sessionId) {
                        formData.append('session_id', this.sessionId);
                    }

                    const response = await fetch('http://localhost:5052/voice_message', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) {
                        throw new Error(`Server error: ${response.status} ${response.statusText}`);
                    }

                    const result = await response.json();
                    this.log(`Server response: ${JSON.stringify(result)}`);

                    // Update session ID
                    if (result.session_id) {
                        this.sessionId = result.session_id;
                    }

                    // Display user's transcribed message
                    if (result.transcript) {
                        this.addMessage(result.transcript, 'user');
                    }

                    // Display AI response
                    if (result.response) {
                        this.addMessage(result.response, 'assistant');
                    }

                    // Play audio response if available
                    if (result.audio_url) {
                        await this.playAudioResponse(`http://localhost:5052${result.audio_url}`);
                    }

                    this.updateStatus('Ready to talk', 'ready');

                } catch (error) {
                    this.log(`Server communication error: ${error.message}`);
                    this.updateStatus('Connection failed', 'error');
                    this.addMessage(`‚ùå Server error: ${error.message}`, 'error');
                    this.addMessage('Make sure server is running: python elevenlabs_integrated_server.py', 'system');
                }
            }

            async playAudioResponse(audioUrl) {
                try {
                    this.log('Playing audio response...');
                    this.updateStatus('Playing response...', 'active');

                    const audio = new Audio(audioUrl);
                    audio.onended = () => {
                        this.updateStatus('Ready to talk', 'ready');
                    };
                    audio.onerror = () => {
                        this.log('Audio playback error');
                        this.updateStatus('Ready to talk', 'ready');
                    };
                    
                    await audio.play();

                } catch (error) {
                    this.log(`Audio playback error: ${error.message}`);
                    this.updateStatus('Ready to talk', 'ready');
                }
            }

            async testConnection() {
                try {
                    this.updateStatus('Testing server connection...', 'connecting');
                    
                    const response = await fetch('http://localhost:5052/status');
                    if (!response.ok) throw new Error('Server not responding');
                    
                    const status = await response.json();
                    this.log(`Server status: ${JSON.stringify(status)}`);
                    
                    this.updateStatus('Server connected ‚úì', 'ready');
                    this.addMessage(`Connected to server on port 5052`, 'system');
                    
                    if (status.openai_configured) {
                        this.addMessage(`‚úÖ Voice AI ready`, 'system');
                        this.getGreeting();
                    } else {
                        this.addMessage(`‚ö†Ô∏è OpenAI API key needed for voice AI`, 'system');
                        this.addMessage(`Agent ready: ${status.agent_id}`, 'system');
                    }
                    
                    setTimeout(() => {
                        this.updateStatus('Ready to talk', 'ready');
                    }, 2000);

                } catch (error) {
                    this.log(`Connection test failed: ${error.message}`);
                    this.updateStatus('Server offline', 'error');
                    this.addMessage('‚ùå Server not running', 'error');
                    this.addMessage('Run: python elevenlabs_integrated_server.py', 'system');
                }
            }

            async getGreeting() {
                if (this.hasGreeted) return;
                
                try {
                    this.updateStatus('Getting greeting...', 'connecting');
                    
                    const response = await fetch('http://localhost:5052/greeting', {
                        method: 'POST'
                    });
                    
                    if (response.ok) {
                        const result = await response.json();
                        this.log(`Greeting received: ${result.text}`);
                        
                        this.sessionId = result.session_id;
                        this.hasGreeted = true;
                        
                        this.addMessage(result.text, 'assistant');
                        
                        if (result.audio_url) {
                            await this.playAudioResponse(`http://localhost:5052${result.audio_url}`);
                        }
                        
                        this.updateStatus('Ready to talk', 'ready');
                    }
                    
                } catch (error) {
                    this.log(`Greeting error: ${error.message}`);
                }
            }
        }

        // Global instance
        const voiceAssistant = new VoiceAssistant();

        // Global functions for button events
        function startRecording() {
            voiceAssistant.startRecording();
        }

        function stopRecording() {
            voiceAssistant.stopRecording();
        }

        // Initialize on load
        window.addEventListener('load', () => {
            voiceAssistant.log('Voice Assistant UI loaded');
            voiceAssistant.testConnection();
        });

        // Prevent context menu on long press
        document.getElementById('micButton').addEventListener('contextmenu', (e) => {
            e.preventDefault();
        });
    </script>
</body>
</html>